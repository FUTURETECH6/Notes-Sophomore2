* SRAMï¼šCache(æ¯”å¯„å­˜å™¨æ…¢
* DRAMï¼šMem

| Memory  technology | Typical  access time   | Cost  per GByte (2004) |
| ------------------ | ---------------------- | ---------------------- |
| SRAM               | 0.5-5ns                | \$4000-\$10,000        |
| DRAM               | 50-70ns                | \$100-\$200            |
| Magnetic  disk     | 5,000,000-20,000,000ns |                        |

# å±‚æ¬¡åŒ–è®¾è®¡

* æ—¶é—´ç›¸å…³æ€§(temporal locality)
    * ä¸€ä¸ªä¸œè¥¿è¢«ç”¨äº†ï¼Œå¤§æ¦‚ç‡è¿‡ä¸€ä¼šä¼šè¢«å†ç”¨
    * å¾ªç¯ç»“æ„
* ç©ºé—´ç›¸å…³æ€§(spatial locality)
    * ä¸€ä¸ªä¸œè¥¿è¢«ç”¨äº†ï¼Œå‘¨å›´çš„ä¸œè¥¿å¤§æ¦‚ç‡è¿‡ä¸€ä¼šä¼šè¢«å†ç”¨
    * é¡ºåº

Our initial focus:  two levels (upper, lower)

* block: minimum unit of data (block) for transfers
* hit: data requested is in the upper level(æ¯”å¦‚åœ¨Cacheä¸­hitäº†å°±ä¸ç”¨å»Memoryæ‰¾)
    * **HitTime**: The time to access the upper level of the memory hierarchy, which includes the time needed to determine whether the access is a hit or a miss. åœ¨upperæ‰¾åˆ°çš„æ—¶é—´(åŒ…æ‹¬å†³å®šæ˜¯å¦hitçš„æ—¶é—´)
* miss: data requested is not in the upper level
    * DMCæ–¹æ³•ä¸­Cacheä¸­æ‰€éœ€çš„å•å…ƒæ ¼è¢«å ç”¨äº†ä¹Ÿå«miss
    * **Miss Penalty**: The time to replace a block in the upper level with the corresponding block from the lower level, plus the time to deliver this block to the processor. 
    * æ²¡æ‰¾åˆ°ä¹Ÿéœ€è¦åŠ ä¸Šhittimeï¼šå¦‚90%hitï¼Œ10%missï¼Œæ€»æ—¶é—´ä¸ºï¼šHitTime\*100% + MissPenalty\*10%

```mermaid
graph LR
subgraph CPU
	Reg
	Cache_L1
end
Reg
-->Cache_L1
-->Cache_L2
-->Memory
-->Disk
```

# Cache

## æ˜ å°„æ–¹å¼

é¦–å…ˆä¸¤ä¸ªé—®é¢˜

* å¦‚ä½•çŸ¥é“æ•°æ®åœ¨ä¸åœ¨é‡Œé¢ï¼Ÿ
* å¦‚æœçŸ¥é“ä¸åœ¨é‡Œé¢ï¼Œè¦æ€ä¹ˆæ‰¾ï¼Ÿè¦ç”¨å“ªä¸ªä½ç½®æ¥è®¿å¯¼å…¥çš„æ•°æ®

==Indexå…¨éƒ¨æ˜¯æ ¹æ®Set(æ˜¾å¼æˆ–éšå¼)è€Œä¸æ˜¯Blockæ¥ç®—çš„==

### Direct Mapped(2L)

**åˆ†å—**ï¼šä¾‹å¦‚1024Word(4Byte/Word)çš„å†…å­˜ï¼Œåˆ†ä¸º256å—ï¼Œåˆ™ç¬¬61ä¸ªWordçš„ä¸»å­˜åœ°å€ä¸º000011(å—å·)11(åŒºå†…å—å·)01(å—å†…åœ°å€)

Memoryä¸­çš„æ•´ä¸ªBlockçš„å†…å®¹è¢«å…¨éƒ¨å­˜åœ¨Cacheä¸­

`Tag = BlockAddr_in_Memory // BlockNum_in_Cache`

`CacheIndex = BlockAddr_in_Memory % BlockNum_in_Cache`

`Offset = ByteAddr_in_Memory % BlockSize`

<img src="assets/image-20200415110455204.png" style="zoom:33%;" />

è™½ç„¶å®¹æ˜“ä¸å‡åŒ€ï¼Œä½†æ˜¯é€Ÿåº¦éå¸¸å¿«(è®¿é—®ä¸€æ¬¡å³å¯)



<img src="assets/image-20200415111200115.png" style="zoom:33%;" />

Tagæ˜¯æŒ‡ç¤ºè¦æ‰¾çš„ä¸œè¥¿çš„Memoryå¯¹åº”åœ¨Blockä¸­çš„Byteåœ°å€(ä¾‹å¦‚ä¸‹é¢ä¾‹é¢˜ä¸­å°±æ˜¯4ä½çš„)

Indexæ˜¯æŒ‡ç¤ºBlockåœ°å€çš„(ä¾‹å¦‚ä¸‹é¢ä¾‹é¢˜ä¸­å°±æ˜¯10ä½çš„)

`{tag, index}`åˆèµ·æ¥å°±æ˜¯å®é™…çš„åœ°å€(å¿…é¡»æ˜¯æŒ‰Byteè€Œä¸æ˜¯Word)

`Addr_bit = tag_bit + block_bit + byteOffset_bit + valid_bit`

<img src="assets/image-20200415111451881.png" style="zoom: 40%;" />

<img src="assets/image-20200415111248532.png" style="zoom: 40%;" />

> How many total bits are required for a direct-mapped **cache** 16KB of data and 4-word blocks, assuming a 32-bit address?
>
> * ~~16KB=4KWord=2^12^ words~~
> * ~~One block=4 words = 2^2^  words~~ 
> * Number of blocks (index bit) = 2^12^ Ã· 2^2^ = 2^10^ blocks(Cacheä¸­çš„BlockNumå’ŒIndexSizeæ˜¯ç›¸ç­‰çš„ï¼Œå› æ­¤indexæ˜¯10ä½çš„)
> * Data bits of block =4Ã—32=128 bits\
> * <u>Tag bits  = address - index - blockSize(byte offset width) =32 - 10 - 4 =18 bits</u>  ï¼Ÿï¼Ÿ(è¿™ä¸ªå¹¶ä¸èƒ½ç”±å…¶ä»–çš„ç®—å‡ºæ¥ï¼Œå› ä¸ºæ²¡å‘Šè¯‰ä½ æ˜ å°„åˆ°çš„Memoryå¤šå¤§ï¼Œåªèƒ½ç”¨åœ°å€çº¿çš„ä½æ•°æ¥åæ¨ï¼Œç”±æ­¤å†æ¨å‡ºMemory = 2^18^ *16KB = 4GB) ==Validå’ŒDirtyä¸ç®—åœ¨åœ°å€ä½é‡Œ==
> * Valid bit = 1 bit
> * Total Cache size = 2^10^ Ã— (128+18+1)= 2^10^Ã—147= 147 Kbits= 18.4KB
> * It is about [1.15](147/128=18.4/16) times as many as needed just for the data

**ç‰¹ç‚¹**

* Cacheåˆ©ç”¨ç‡ä½
* **æ›¿æ¢é€Ÿåº¦å¿«**
* **å—å†²çªç‡é«˜**
* æ·˜æ±°ç®—æ³•ç®€å•
* é€‚åˆäºå¤§å®¹é‡Cache[ä½åˆ©ç”¨ç‡ã€æ·˜æ±°ä¸è‡³äºå¤ªå¤æ‚]

Ex. 1-word Block

<img src="assets/image-20200421200008644.png" style="zoom:33%;" />

### Fully-Associative(1L)

**åˆ†å—**ï¼šä¾‹å¦‚1024Word(4Byte/Word)çš„å†…å­˜ï¼Œåˆ†ä¸º256å—ï¼Œåˆ™ç¬¬61ä¸ªWordçš„ä¸»å­˜åœ°å€ä¸º00001111(å—å·)01(å—å†…åœ°å€)

Tagç›´æ¥å­˜å‚¨`BlockAddr_in_Memory`ï¼Œ

(è¿™ä¸ªæ‰«æä¸æ˜¯å·¨æ…¢ï¼Ÿï¼Ÿ

**ç‰¹ç‚¹**

* Cacheåˆ©ç”¨ç‡é«˜
* **æ›¿æ¢é€Ÿåº¦æ…¢**
* **å—å†²çªç‡ä½**
* æ·˜æ±°ç®—æ³•å¤æ‚
    * Random, LRU, FIFO
* é€‚åˆäºå°å®¹é‡Cache[é«˜åˆ©ç”¨ç‡ã€ä¸è‡³äºå› ä¸ºæ·˜æ±°å¤æ‚è€Œå¯¼è‡´æ—¶é—´å¾ˆæ…¢]

Ex. 1-word Blocks(Assume cache has 4 blocks)

<img src="assets/image-20200421200051843.png" style="zoom:33%; " />

### Set-Associative(3L)

ä¸€ä¸ªCacheå¤šç»„ï¼Œæ¯ç»„å¤šå—

`SetIndex_in_Cache = SetIndex_in_Memory % SetNum_in_Cache`

\\                                     `= (BlockAddr_in_Memory / BlockNum_in_Set) % SetNum_in_Cache`

**n-way set associative**ï¼šä¸€ä¸ªsetæœ‰nä¸ªblock

Ex. 2-Way Set-Associative Cache(1 word/block; 2 blocks/set; 4 blocks/cache; hence 2 sets per cache)

<img src="assets/image-20200421200135739.png" style="zoom:33%;" />

### æ˜ å°„æ–¹å¼åŒºåˆ«

[æ˜ å°„æ–¹å¼å¯¹æ€§èƒ½çš„å½±å“](# æ˜ å°„æ–¹å¼å¯¹æ€§èƒ½çš„å½±å“)

* DMï¼šæµ™æ±Ÿä»£è¡¨åªèƒ½ä½201
* FAï¼šæµ™æ±Ÿä»£è¡¨éšä¾¿ä½
* SAï¼šæµ™æ±Ÿä»£è¡¨ç»™5ä¸ªæˆ¿é—´
    * å³ï¼šä»»æ„æ¨¡ç»„æ•°ä¸ºkçš„éƒ½å¯ä»¥è¿›åˆ°index=kçš„setï¼Œç„¶åå†çœ‹è¦å»æ›¿æ¢è¿™ä¸ªseté‡Œçš„å“ªä¸ªblock

<img src="assets/image-20200417090807882.png" style="zoom: 50%;" />

### ç‰©ç†åœ°å€

| Block_Addr      | Block_Addr     |                  |
| --------------- | -------------- | ---------------- |
| Tag             | Index          | offset           |
| ç¬¬å‡ ä¸ªset/block | (Index of Set) | å—å†…çš„byte index |
|                 | Index of Block |                  |

* The Index field selects
    * The set, in case of a set-associative cache
    * The block, in case of a direct-mapped cache
    * Has as many bits as `log2(#sets)` for set-associative caches, or `log2(#blocks)` for direct-mapped caches
    * ==Indexå…¨éƒ¨æ˜¯æ ¹æ®Set(æ˜¾å¼æˆ–éšå¼)è€Œä¸æ˜¯Blockæ¥ç®—çš„==
* The Byte Offset field selects
    * The byte within the block
    * Has as many bits as `log2(size of block)`
* The Tag is used to find the matching block within a set or in the cache
    * Has as many bits as `Address_size â€“ Index_size â€“ Byte_Offset_Size`



**Ex**. CacheSize = 64KB; 4 words/block; 4 bytes/word; physical address: 32bits

|                   | tag  | inedx | offset |
| ----------------- | ---- | ----- | ------ |
| Directed-Mapped   | 16   | 12    | 4      |
| Fully-Associative | 28   | 0     | 4      |
| 2-way associative | 17   | 11    | 4      |
| 4-way associative | 18   | 10    | 4      |



## Cache R/W

### Handling Read

å…ˆæ‰¾å¯¹åº”indexçš„ï¼Œå¦‚æœVæ˜¯ä½ç”µå¹³æˆ–è€…tagä¸­çš„å†…å®¹ä¸å¯¹ï¼Œåˆ™æ˜¯miss

**Read miss**(å†¯è¯ºä¾æ›¼ï¼Œå› ä¸ºæ··åœ¨ä¸€èµ·missæ¦‚ç‡ä¼šåŠ å¤§)

* instruction cache miss
* data cache miss

inst cache miss4

1. **stall(æŒ‚èµ·) the CPU**: Send the original PC value (current PC-4) to the memory. (ç­‰ä½ å»å†…å­˜æ‰¾å›æ¥æˆ‘å¯ä»¥å…ˆå»å®Œæˆå…¶ä»–ä¸€å †ç¨‹åºäº†)
2. **fetch block from memory**: Instruct main memory to perform a read and wait for the memory to complete its access.
3. **deliver to cache**(è¿™æ­¥åˆ«æ¼äº†): Write the cache entry, putting the data from memory in the data portion of the entry, writing the upper bits of the address (from the ALU) into the tag field, and turning the valid bit on.
4. **restart CPU read**: Restart the instruction execution at the first step, which will <u>refetch the instruction again</u>, this time <u>finding it in the cache</u>. (Read Hit)

å†·å¯åŠ¨ï¼šå¼€æœºçš„æ—¶å€™ï¼ŒOSä¸ºäº†å¼€æœºä¼šæŠŠCacheå…¨éƒ¨å†™æ»¡ï¼Œè¿™æ—¶å€™ä¼šå¾ˆæ…¢ï¼›ä¹‹åOSå°±åœ¨Cacheä¸­å¸¸é©»äº†å› æ­¤é€Ÿåº¦å°±å¿«äº† (è®ºDDR4çš„é‡è¦æ€§

### Handling Write

* Write hits:  Difference Strategy
    * write-back: Cause Inconsistent (ä¹‹åå†å†™åˆ°å†…å­˜)
        * Wrote the data into only the data cache
        * Strategy ---- write back data from the cache to memory later (laterä¸€èˆ¬æ˜¯æŒ‡ç¨‹åºç»“æŸä¹‹å)
        * Fastï¼Œä¸¤è€…ç›¸å·®å¾ˆå¤§ç”¨è¿™ç§
        * éœ€è¦åŠ ä¸€ä¸ªdirtyä½æ¥è¿›è¡Œåˆ¤æ–­
    * write-through: Ensuring Consistent (æ€»æ˜¯å†™åˆ°å†…å­˜ï¼Œ(ä¸€å†™åˆ°åº•through))
        * Write the data into both the memory the cache
        * Strategy ---- writes always update both the cache and the memory
        * Slower----write bufferï¼Œä¸¤è€…å·®è·ä¸å¤§ç”¨è¿™ç§
* Write misses(å†™ä¸œè¥¿ï¼Œtagå¯¹ä¸ä¸Š):
    * read the entire block from memory into the cache, then write the word using \-back or \-through
    * Write allocate 
        * The block is loaded into the cache on a miss before anything else occurs.
        * çœ‹è„ä½
            * 1ï¼šå…ˆæŠŠåŸæ¥ä¸œè¥¿å†™åˆ°å†…å­˜ï¼Œå†ç”¨æ–°å€¼å†²æ‰
            * 0ï¼šæ²¡è¢«å†™è¿‡ï¼Œç›´æ¥å†²
    * Write around (no write allocate) 
        * The block is only written to main memory 
        * It is not stored in the cache. 
    * In general, write-back caches use write-allocate , and write-through caches use write-around. 

**è„ä½**

* The bit indicates that its associated block of cache has been modified and has not been saved to memory yet. [What does 'dirty' mean in the context of caching? - Quora](https://www.quora.com/What-does-dirty-mean-in-the-context-of-caching)
* CPUå‘Cacheä¸Šçš„æŸBlockå†™è¿‡ä¸œè¥¿ä¹‹åBlockçš„dirtyBitè¢«ç½®ä½ã€‚ä¹‹åè¦æ›´æ–°Cacheçš„æ—¶å€™ï¼Œå¦‚æœdirtyæ˜¯1å°±å¿…é¡»å…ˆæŠŠå½“å‰çš„å†™åˆ°Memory(æ­¤æ—¶å¤ä½ï¼Ÿ)å†æ›´æ–°ï¼Œå¦‚æœæ˜¯0å°±ç›´æ¥æ›´æ–°ã€‚
* æ­¤å¤„çš„è„ä½(Cache->Mem)å’Œè™šæ‹Ÿå†…å­˜ä¸­çš„(Mem->Disk)å·®ä¸å¤šï¼Œå°±æ˜¯ä½ç½®ä¸ä¸€æ ·è€Œå·²

## æ€»ç»“

### æ›¿æ¢æ–¹æ¡ˆ

* Randomï¼šç®€å•

* FIFOï¼šè®¡ç®—é‡å¤§ï¼Œè¿˜å¾—æœ‰ç¡¬ä»¶æ¥è®¡ç®—æ—¶é—´

* LRU(Least Recently Used)ï¼šè®¡ç®—é‡å¤§ï¼Œè¿˜å¾—æ¯æ¬¡éƒ½æ›´æ–°è°æ˜¯æœ€è¿‘ä½¿ç”¨çš„

    * The most commonly used scheme is least recently used (LRU), which we used in the previous example. In an LRU scheme, the block replaced is the one that has been unused for the longest time.

        For a two-way set associative cache, the LRU can be implemented easily. We could keep a single bit in each set. We <u>set the bit whenever a specific block in the set is referenced</u>, and reset the bit whenever another block is referenced.

        As associativity increases, implementing LRU gets harder.

## Memory Organization

**ç©ºé—´ç›¸å…³æ€§**

ã€‚ã€‚ã€‚ã€‚

**ä¸‰ç§ç­–ç•¥**

<img src="assets/image-20200421214324844.png" style="zoom: 25%;" />

### Basic

å‡è®¾ï¼šä¸€ä¸ªclkå‘é€åœ°å€ï¼›15ä¸ªclkè®¿é—®åˆå§‹åŒ–(æ‰¾åˆ°åœ°å€)ï¼›1ä¸ªclkä¼ 1 wordæ•°æ®ï¼›4 words/block, 4 bytes/words

å› æ­¤1wordæ•°æ®è¦17clkï¼Œä¼ 1 blockè¦`Miss Penalty = 1 + 4 Ã—(1 + 15) = 65clk`(åœ°å€åªç”¨ä¼ ä¸€æ¬¡)

${\rm Bandwidth} å¸¦å®½ = \frac{16B}{65clk} \approx \frac14$

<u>å¸¦å®½è¡¨ç¤ºä¸€ä¸ªå‘¨æœŸèƒ½ä¼ å¤šå°‘å­—èŠ‚çš„æ•°æ®</u>

### Wide

2Wordsçš„æ•°æ®å®½

éœ€è¦`Miss Penalty = 1 + 2 Ã—(15 + 1) = 33clk` (å‘åœ°å€ä¸€æ¬¡ï¼Œ(è¯»+ä¼ )ä¸¤æ¬¡)

${\rm Bandwidth} å¸¦å®½ = \frac{16B}{33clk} \approx 0.48$

4wordsçš„æ•°æ®å®½

éœ€è¦`Miss Penalty = 1 + 1 Ã— (15 + 1) = 17clk` (å‘åœ°å€ä¸€æ¬¡ï¼Œ(è¯»+ä¼ )ä¸€æ¬¡)

${\rm Bandwidth} å¸¦å®½ = \frac{16B}{17clk} \approx 0.98$

### Four-way interleaved

æ¯æ¬¡éƒ½æŠŠå…¶ä»–çš„å‡†å¤‡å¥½

éœ€è¦`Miss Penalty = 1 + 15 + (4 Ã— 1) = 20clk`(å‘åœ°å€ä¸€æ¬¡ï¼Œè¯»ä¸€æ¬¡ï¼Œä¼ å‡ºå››æ¬¡)

${\rm Bandwidth} å¸¦å®½ = \frac{16B}{20clk} \approx 0.8$

> ä¸ºä»€ä¹ˆæ¯”Wideå¥½ï¼Ÿæ˜æ˜å¸¦å®½æ›´é«˜ï¼Ÿ
>
> \\	å› ä¸ºåŠ æ€»çº¿å¾ˆè´µ

æ³¨æ„å››ä¸ªå†…å­˜å—çš„åœ°å€

<img src="assets/image-20200422105323845.png" style="zoom:33%;" />

## Cacheæ€§èƒ½

`CPU time = (CPU execution clock cycles ô°ƒ+ Memory-stall clock cycles) Ã— Clock cycle time`

`Memory-stall clock cycles ô°€= (Read-stall cycles ô°ƒ+ Write-stall cycles)`

è¯»æ“ä½œé˜»å¡çš„å‘¨æœŸï¼š`Read_stall_cycles = (Reads/Program) Ã— Read_miss_rate Ã— Read_miss_penalty`

å†™æ“ä½œé˜»å¡çš„å‘¨æœŸï¼š`Write_stall_cycles = ((Writes/Program) Ã— Write_miss_rate Ã— Write_miss_penalty) + (Write_buffer_stalls)`

å†™ç¼“å†²åŒºé˜»å¡ï¼š`Write_buffer_stalls`ï¼šä¸ªäººç†è§£åº”è¯¥å€¼å¾—æ˜¯è¿ç»­å¤šæ¬¡å†™æ“ä½œä¸­ï¼Œä¸‹ä¸€æ¬¡å¾—ç­‰ä¸Šä¸€æ¬¡å†™å®Œæ‰å¯ä»¥å†™ã€‚å–å†³äºé¢‘ç‡å’Œwriteçš„æ—¶æœº(ï¼Ÿ)ï¼Œå› æ­¤æ²¡åŠæ³•é‡åŒ–è®¡ç®—ã€‚

å­˜å‚¨å™¨é˜»å¡æ—¶é’Ÿå‘¨æœŸæ•°ï¼š`Memory-stall clock cycles = (Memory_accesses/Program) Ã— Miss_rate Ã— Miss_penalty = (Instructions/Program) Ã— (Misses/Instruction) Ã— Miss_penalty`

### buffer



### Blockå¤§å°å¯¹æ€§èƒ½å½±å“

BlockğŸ‘†ï¼ŒIndexğŸ‘‡

| Program | Block size in  words | Instruction  miss rate | Data miss rate | Effective  combined miss rate |
| ------- | -------------------- | ---------------------- | -------------- | ----------------------------- |
| gcc     | 1                    | 6.1%                   | 2.1%           | 5.4%                          |
|         | 4                    | 2.0%                   | 1.7%           | 1.9%                          |
| spice   | 1                    | 1.2%                   | 1.3%           | 1.2%                          |
|         | 4                    | 0.3%                   | 0.6%           | 0.4%                          |

### è¯„ä¼°æ€§èƒ½

* Miss Penaltyå½±å“å†·å¯åŠ¨é€Ÿåº¦ä¹‹ç±»çš„
* Miss Rate

ä¸¤ç§å¯åŠ¨æ–¹å¼

* å†·å¯åŠ¨æ…¢ï¼Œä½†æ˜¯å¼€æœºä¹‹åéƒ½å¾ˆæµç•…

* å†·å¯åŠ¨å¿«ï¼Œä½†æ˜¯å¼€æœºä¹‹åå¾—ä¸æ–­åŠ è½½æ‰€ä»¥ä¼šå¡](# æ˜ å°„æ–¹å¼)

    ã€‚ã€‚ã€‚

    CPU_time = I Ã— CPI Ã— clk_time;

    CPU_time = (CPU_execution_cycles + Memory_stall_cycles) Ã— clk_time

    Memory-stall clock cycles = # of instructions Ã— miss ratio Ã— miss penalty = Read-stall cycles + Write-stall cycles

    ã€‚ã€‚ã€‚

    åŠ ä¸ŠR/Wï¼š

    ã€‚ã€‚ã€‚

#### æ˜ å°„æ–¹å¼å¯¹æ€§èƒ½çš„å½±å“

å…ˆçœ‹[è¿™é‡Œ](# æ˜ å°„æ–¹å¼)

Ex. Given the following sequence of block addresses: 0,8,0,6,8, find the number of misses for each cache organization. (each consisting of four one-word blocks. )

**direct-mapped**: 5 misses

| Memory block | Hit or miss | Set 0   | Set 1   | Set 2   | Set 3   |
| ------------ | ----------- | ------- | ------- | ------- | ------- |
|              |             | Block 0 | Block 1 | Block 2 | Block 3 |
| 0            | Miss        | M[0]    |         |         |         |
| 8            | Miss        | M[8]    |         |         |         |
| 0            | Miss        | M[0]    |         |         |         |
| 6            | Miss        | M[0]    |         | M[6]    |         |
| 8            | Miss        | M[8]    |         | M[6]    |         |

**fully-associative**: 3 misses

| Memory block | Hit or miss | Set 0   | Set 0  | Set 0  | Set 0  |
| ------------ | ----------- | ------- | ------- | ------- | ------- |
|              |             | Block 0 | Block 1 | Block 2 | Block 3 |
| 0            | Miss        | M[0]     |         |         |           |
| 8            | Miss        | M[0]     | M[8]    |         |           |
| 0            | Hit         | M[0]     | M[8]    |         |           |
| 6            | Miss        | M[0]     | M[8]    | M[6]    |           |
| 8            | Hit         | M[0]     | M[8]    | M[6]    |           |

**set-associative**: 4 misses

| Memory block | Hit or miss | Set 0   | Set 0  | Set 1  | Set 1  |
| ------------ | ----------- | ------- | ------- | ------- | ------- |
|              |             | Block 0 | Block 1 | Block 2 | Block 3 |
| 0            | Miss        | M[0]     |         |         |           |
| 8            | Miss        | M[0]     | M[8]    |         |           |
| 0            | Miss        | M[0]     | M[8]    |         |           |
| 6            | Miss        | M[0]     | M[6]    |         |           |
| 8            | Miss        | M[8]     | M[6]    |         |           |

### è®¡ç®—

> Assume:
>
> * instruction cache miss rate = 2%
> * data cache miss rate = 4%
> * CPI without any memory stalls = 2
> * miss penalty = 100 cycles
> * The frequency of all loads and stores in gcc is 36%,as we see in Figure 3.26, on page 288.
>
> Question: How faster a processor would run with a perfect cache?
>
> Answer:
>
> * Instruction miss cycles = IÃ—2%Ã—100 =2.00I
> * Data miss cycles = IÃ—36%Ã—4%Ã—100 =1.44I
> * Total memory-stall cycles = 2.00I+ 1.44I =3.44I
> * CPI with stall = CPI with perfect cache + total memory-stalls
>     \\                      = (2 + 3.44 )I = 5.44I
> * CPU_time_with_stall/CPU_time_with_perfect_cache(perfect is ) = (IÃ—CPI_stallÃ—Clock_cycle)/(IÃ—CPI_perfectÃ—Clock_cycle) = CPI_stall/CPI_perfect = 5.44/2 = 2.72

## ä¼˜åŒ–æ€§èƒ½

### é™ä½Miss Rate

### é™ä½Miss Penalty

å¤šçº§ç¼“å­˜

Ex. å‡è®¾åŸæ¥CPI of 1.0 on a 5GHz machine with a 2% miss rate, 100ns DRAM accessï¼›ç°åœ¨Adding 2nd level cache with 5ns access time decreases miss rate to 0.5%(2%ä¸­æœ‰99.5%å¯ä»¥åœ¨äºŒçº§ç¼“å­˜æ‰¾åˆ°)

Miss penalty to main memory is `(100ns)/(0.2ns/clk) = 500clk`

Miss penalty with levels of cache without access main memory is `(5ns)/(0.2ns/clk) = 25clk`

The **CPI** with Two level of cache is `1.0 + primary_stall_per_inst + secondary_stall_per_inst = 1 + 2% Ã— 25 + 0.5% Ã— 500 = 1 + 0.5 + 2.5 = 4.0`

æœ¬æ¥æ˜¯`1 + 2% Ã— 500 = 11.0`ï¼Œæ˜¾ç„¶å¿«äº†å¾ˆå¤š

#  Virtual Memory

Page offsetï¼šæŒ‰é¡µç®—çš„ï¼Œä¸€èˆ¬å¾ˆå¤§ (Pageå¯¼ä¸€æ¬¡(Mem<==>Disk)è¦å¾ˆä¹…ï¼Œå› æ­¤å¾—å°½é‡åšå¤§)

Page Fault: the data is not in memory, retrieve it from disk

* huge miss penalty, thus pages should be fairly large (e.g., 4KB)ï¼Œå¤ªå¤§ä¹Ÿä¸è¡Œï¼Œå¤ªæ…¢äº†
* reducing page faults is important (LRU is worth the price)
* can handle the faults in software instead of hardware
* using write-through is too expensive so we use write back (ä¹‹åå†™)

**MMU(Memory Management Unit)ç®¡ç†å­˜å‚¨å™¨ä¸ç‰©ç†å­˜å‚¨å™¨**

é‡‡ç”¨é¡µè¡¨æ¥åˆ¤æ–­PCUè®¿é—®çš„å†…å®¹æ˜¯å¦åœ¨ä¸»å­˜å½“ä¸­ï¼Œå¹¶ä¸MMUé…åˆå®ç°é€»è¾‘åœ°å€å’Œç‰©ç†åœ°å€¼ä¹‹é—´çš„è®¿é—®

VPN(Virtual Page Num)è™šæ‹Ÿé¡µå·

PPNç‰©ç†é¡µå·

